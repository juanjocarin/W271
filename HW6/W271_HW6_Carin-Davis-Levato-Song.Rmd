---
title: "**W271**-2 -- Spring 2016 -- **HW 6**"
author: "***Juanjo Carin, Kevin Davis, Ashley Levato, Minghu Song***"
date: "*March 16, 2016*"
output:
   pdf_document:
     fig_caption: yes
     toc: yes
numbersections: false
geometry: margin=1in
options: width=30
fontsize: 10pt
linkcolor: blue
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyhead[LO,LE]{Carin, Davis, Levato, Song}
- \fancyhead[CE,CO]{W271 -- HW 6 -- \leftmark}
- \fancyhead[RE,RO]{\rightmark}
- \fancyfoot[LO,LE]{UC Berkeley -- MIDS}
- \fancyfoot[CO,CE]{Spring semester 2016}
- \fancyfoot[RE,RO]{\thepage}
- \renewcommand{\headrulewidth}{0.5pt}
- \renewcommand{\footrulewidth}{0.5pt}
---

**********

\pagebreak

# Exercises

```{r, echo = FALSE, warning = FALSE}
require(knitr, quietly = TRUE)
read_chunk('code/W271_HW6_Carin-Davis-Levato-Song.R')
opts_chunk$set(message = FALSE, warning = FALSE)
opts_chunk$set(fig.width = 4, fig.height = 3)
# Set path to data here (don't use setwd() inside a chunk!!!)
opts_knit$set(root.dir = './data')
```

```{r Libraries-Functions-Constants, echo = FALSE}
```

## Exercise 1

a. **Discuss the mean and variance functions and how the similarities and differences from those we studied in classical linear model.**

The mean function for a time series is deinfed by the function:

$$ \mu_x (t) = E(x_t) = \int_{- \infty}^{+ \infty} x_t f_t(x_t)dx_t$$

Where the probability density function $f_t$ is the marginal distribution of $x_t$ derived from the complete joint probability distribution $F(c_1,c_2,\dots,c_n)=\Pr(x_{t_1} \leq c_1, x_{t_2} \leq c_2, \dots, x_{t_n} \leq c_n)$.

This function has a time component so the mean could be different in different time periods (if it is not, the time series is *stationary in the mean*). This is different from a mean in classical linear models where the mean is always constant.

The variance functions for a time series analys is defined by the function:

$$\sigma_x^2(t) = E\left[(x_t-\mu_x(t))^2\right] = \int_{- \infty}^{+ \infty} (x_t-\mu_x(t))^2f_t(x_t)dx_t$$

Again this function is time dependent, which means it may vary with time unlike the variance in a classical linear model. If it is constant, the time series is *stationary in the variance* or *variance stationary*.

In both cases we are calculating expectations over the ensemble---the set of all time series that could be generated by the stochastic process.

b. **Define strict and weak stationarity**

<!--Statonarity indicates the parameter is consistent is accross time.-->

Strict stationary occurs when the joint distributions $F(x_{t_1}, ..., x_{t_n})$ and $F(x_{t_{1+m}}, ..., x_{t_{n+m}})$ are the same for all $t_1,\dots,t_n,m$, implying that the distribution is unchanged for any time shift $m$.

A time series is *weakly stationary* (also called *second-order stationary*) when it is mean and variance stationary and its autocovariance $Cov(x_t, x_{t+k})$ depends only on the time shift $k$ (it is then written as $\gamma_k$. Once a distribution assumption is imposed, the time series can be completely characterized by its mean and covariance structure.

**********

\pagebreak



## Exercise 2

a. **Generate a zero-drift random walk model using 500 simulation.**

```{r Question2-a, echo = c(3:6)}
```


b. **Provide the descriptive statistics of the simulated realizations. The descriptive statistics should include the mean, standard deviation, 25th, 50th, and 75th quantiles, minimum, and maximum.**

```{r Question2-b, echo = c(6:7)}
```


c. **Plot the time-series plot of the simulated realizations.**

See the last part of this Exercise in the following page.


d. **Plot the autocorrelation graph.**

See the last part of this Exercise in the following page.


\pagebreak

e. **Plot the partial autocorrelation graph.**

```{r Question2-e, echo = FALSE, fig.width = 6, fig.height = 4.5, fig.cap = "Time-series plot, histogram, correlogram, and partial autocorrelogram of the 500 simulation of a zero-drift random walk"}
```

**********

\pagebreak



## Exercise 3

a. **Generate a random walk with drift model using 500 simulation, with the drift = 0.5.**

```{r Question3-a, echo = c(4:7)}
```


b. **Provide the descriptive statistics of the simulated realizations. The descriptive statistics should include the mean, standard deviation, 25th, 50th, and 75th quantiles, minimum, and maximum.**

```{r Question3-b, echo = c(6:7)}
```


c. **Plot the time-series plot of the simulated realizations.**

See the last part of this Exercise in the following page.


d. **Plot the autocorrelation graph.**

See the last part of this Exercise in the following page.


\pagebreak

e. **Plot the partial autocorrelation graph.**

```{r Question3-e, echo = FALSE, fig.width = 6, fig.height = 4.5, fig.cap = "Time-series plot, histogram, correlogram, and partial autocorrelogram of the 500 simulation of a 0.5-drift random walk"}
```


**********

\pagebreak



## Exercise 4

**Use the series from `INJCJC.csv`.**

a. **Load the data and examine the basic structure of the data using `str()`, `dim()`, `head()`, and `tail()` functions.**

```{r Question4-a, echo = -c(1:4)}
```

```{r Question4-a-2, echo = FALSE}
```

The `r dim(INJCJC_df)[1]` observations (of two variables, `INJCJC` and `INJCJC4`) correspond to $1,300/52=`r 1300/52`$ periods of 52 weeks, i.e., almost 25 years from January 5, 1990, until November 28, 2014.

All observations correspond to Fridays.

```{r Question4-a-3}
```

Since years are slightly longer (by 1 or 2 days) than 52 weeks, some years have 53 Fridays. Those years with 53 Fridays sum up, and as a result (and since the number of observations we have is a multiple of 52) the last year in the sample (2014) does not include all of the Fridays there were that year (there were 1,304 Fridays in that 25-year period from 1990 to 2014).

```{r Question4-a-4}
```

Another way to see it: because some years had more than 52 Fridays, each set of 52 observations gradually ends earlier (see the even rows below, that correspond to `week == 52`: December 28, December 27, December 25, December 24...). Hence, the next set of 52 observations start earlier, even in the previous year (see row 8), and the aggregate effect is that the 25th set of 52 observations---which should correspond to 2014---start as early as December 6, 2013, and ends in November 28, 2014.

```{r Question4-a-5}
```


b. **Convert the variables `INJCJC` into a time series object `frequency=52, start=c(1990,1,1), end=c(2014,11,28)`. Examine the converted data series.**

The above parameters may be wrong: according to the [`ts` documentation](http://127.0.0.1:31048/library/stats/html/ts.html), `start` and `end` have to be "*Either a single number or a vector of two integers, which specify a natural time unit and a (1-based) number of samples into the time unit*," i.e., and not a date in `y-m-d` format. If we use the parameters in the instructions, R discards `28` and takes `11` observations from 2014, not the 52 that there really are.

```{r Question4-b, echo = c(4:7)}
```

\pagebreak

We can plot both the original vector and the time series object to confirm this.

```{r Question4-b-2, echo = FALSE, fig.width = 6, fig.height = 4.5, fig.cap = "U.S. Initial Jobless Claims (in thousands) from 5 Jan 1990 to 28 Nov 2014"}
```

Hence, we slightly change the R command to get the proper time series object:

```{r Question4-b-3}
```

The way `ts` works, our time scale does not correspond to the original dates (every Friday between the start and end date, including both) because we've set a fixed frequency of 52 (instead of $365/7 = `r frmt(365/7)`$ if the year is not leap, and $366/7 = `r frmt(366/7)`$ if it is) and the 1st time period is set to the very beginning of the year. Compare the original dates in our dataset with the dates `ts` sets, for the 1st and 52nd observation (while the day and month of the 1st and 52nd observations of each of the 25 subsets will vary, as we have seen, the day and month---and even time---will be fixed in the `ts` object, regardless of the year); the date of the last observation in the "wrong/truncated version" of `INJCJC` is also shown.:

```{r Question4-b-4, echo = c(1, 4)}
```

\small

> This does not happen with montly or quarterly data (and happens to a lesser extent with daily data).

\normalsize

One way to preserve the sampling dates is by using the `xts` library:

```{r Question4-b-5, echo = c(1:2), fig.width = 6, fig.height = 4.5, fig.cap = "U.S. Initial Jobless Claims (in thousands) from 5 Jan 1990 to 28 Nov 2014, using the `xts` package"}
```


\pagebreak

c. **Define a variable using the command `INJCJC.time<-time(INJCJC)`.**


```{r Question4-c, echo = -1}
```


d. **Using the following command to examine the first 10 rows of the data. Change the parameter to examine different number of rows of data.**

> **`head(cbind(INJCJC.time, INJCJC),10)`**


```{r Question4-d, echo = -c(1:2)}
```


\pagebreak

e.

>  1. **Plot the time series plot of `INJCJC`. Remember that the graph must be well labelled.**

```{r Question4-e-1, echo = 3, fig.width = 6, fig.height = 4.5, fig.cap = "U.S. Initial Jobless Claims (in thousands) from 5 Jan 1990 to 28 Nov 2014"}
```

Compare the previous Figure, plotted using `xts`, with the one above: the former shows the proper time scale (starting in January 5, 1990, and ending in November 28, 2014), while the latter covers the full 25-year period.

\pagebreak

>  2. **Plot the histogram of `INJCJC`. What is shown and not shown in a histogram? How do you decide the number of bins used?**

```{r Question4-e-2, echo = 4, fig.width = 6, fig.height = 6, fig.cap = "Histogram of the U.S. Initial Jobless Claims (in thousands) from 5 Jan 1990 to 28 Nov 2014, using different bins"}
```

The histograms tells us nothi ng about the dynamics of the series; e.g., it lets us know that there were a few time periods where the number of Initial Jobless Claims was greater than 600 (thousand), but not when that happened (in the 1st half of 2009).

A good number of bins is one that neither *oversimplifies* the (sample) distribution (i.e., it is not so low that some modes may be hidden) nor shows too much detail that is due to sampling and makes the underlying (real) distribution much more complex than it really is (i.e., it is so high that a low of modes, just due to sampling, are shown). Hence, the best representation in the previous Figure would be the one in the midle.


>  3. **Plot the autocorrelation graph of `INJCJC` series.**

We plot the first 52 correlations (apart from $\rho_0$) just to check all possible seasonality components (incl. annual).

```{r Question4-e-3, echo = 2, fig.width = 6, fig.height = 4.5, fig.cap = "Partial autocorrelation graph of U.S. Initial Jobless Claims from 5 Jan 1990 to 28 Nov 2014"}
```

The autocorrleation decreases exponentially, but very slowly (this is typical of an AR(1) model with a coefficient very close to 1). Nonetheless, we must note that the time series has neither been seasonally nor detrended.

\pagebreak

>  4. **Plot the partial autocorrelation graph of `INJCJC` series.**

```{r Question4-e-4, echo = 2, fig.width = 6, fig.height = 4.5, fig.cap = "Partial autocorrelation graph of U.S. Initial Jobless Claims from 5 Jan 1990 to 28 Nov 2014"}
```

The partial autocorrelation plot makes it evident that this time series was not generated by an AR(1) model. After controlling for the effect of the process at lags 1 and 2, the partial correlation at lags 2 and 3, respectively, is still significant.

\pagebreak

>  5. **Plot a 3x3 Scatterplot Matrix of correlation against lag values.**

```{r Question4-e-5, echo = 2, fig.width = 6, fig.height = 6, fig.cap = "Scatterplot matrix of the correlation of the U.S. Initial Jobless Claims time series against its first 9 own lags"}
```

As the correlogram in Figue 7 suggested, the correlation between the time series and its lagged version is very high, and that correlation decreases very slowly with the lag.


\pagebreak

f.

>  1. **Generate two symmetric Moving Average Smoothers. Choose the number of moving average terms such that one of the smoothers is very smoother and the other one can trace through the dynamics of the series. Plot the smoothers and the original series in one graph.**

```{r Question4-f-1, echo = c(5:6), fig.width = 6, fig.height = 4.5, fig.cap = "U.S. Initial Jobless Claims (in thousands) from 5 Jan 1990 to 28 Nov 2014 (original series plus two Moving Average Smoothers)"}
```

>  2. **Generate two regression smoothers, one being a cubic trend regression and the other being a periodic regression. Plot the smoothers and the original series in one graph.**


```{r Question4-f-2, echo = c(4:11), fig.width = 6, fig.height = 4.5, fig.cap = "U.S. Initial Jobless Claims (in thousands) from 5 Jan 1990 to 28 Nov 2014 (original series plus two Regression Smoothers)"}
```

\pagebreak

>  3. **Generate kernel smoothers. Choose the smoothing parametrs such that one of the smoothers is very smoother and the other one can trace through the dynamics of the series. Plot the smoothers and the original series in one graph.**

```{r Question4-f-3, echo = c(5:6), fig.width = 6, fig.height = 4.5, fig.cap = "U.S. Initial Jobless Claims (in thousands) from 5 Jan 1990 to 28 Nov 2014 (original series plus two Regression Smoothers)"}
```

\pagebreak

>  4. **Generate two nearest neighborhood smoothers. Choose the smoothing parameters such that one of the smoothers is very smoother and the other one can trace through the dynamics of the series. Plot the smoothers and the original series in one graph.**

```{r Question4-f-4, echo = c(5:6), fig.width = 6, fig.height = 4.5, fig.cap = "U.S. Initial Jobless Claims (in thousands) from 5 Jan 1990 to 28 Nov 2014 (original series plus two Nearest Neighborhood Smoothers)"}
```

\pagebreak

>  5. **Generate two LOWESS smoothers. Choose the smoothing parameters such that one of the smoothers is very smoother and the other one can trace through the dynamics of the series. Plot the smoothers and the original series in one graph.**

```{r Question4-f-5, echo = c(5:6), fig.width = 6, fig.height = 4.5, fig.cap = "U.S. Initial Jobless Claims (in thousands) from 5 Jan 1990 to 28 Nov 2014 (original series plus two LOWESS Smoothers)"}
```

\pagebreak

>  6. **Generate two spline smoothers. Choose the smoothing parameters such that one of the smoothers is very smoother and the other one can trace through the dynamics of the series. Plot the smoothers and the original series in one graph.**

```{r Question4-f-6, echo = c(5:6), fig.width = 6, fig.height = 4.5, fig.cap = "U.S. Initial Jobless Claims (in thousands) from 5 Jan 1990 to 28 Nov 2014 (original series plus two Spline Smoothers)"}
```

**********
