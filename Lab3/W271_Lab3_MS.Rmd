---
title: "**W271**-2 -- Spring 2016 -- **Lab 3**"
author: "***Juanjo Carin, Kevin Davis, Ashley Levato, Minghu Song***"
date: "*April 22, 2016*"
output:
   pdf_document:
     fig_caption: yes
     fig_height: 3
     fig_width: 4
     toc: yes
     toc_depth: 2
numbersections: false
geometry: margin=1in
options: width=30
fontsize: 10pt
linkcolor: blue
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyhead[LO,LE]{Carin, Davis, Levato, Song}
- \fancyhead[CE,CO]{W271 -- Lab 3}
- \fancyhead[RE,RO]{\leftmark}
- \fancyfoot[LO,LE]{UC Berkeley -- MIDS}
- \fancyfoot[CO,CE]{Spring semester 2016}
- \fancyfoot[RE,RO]{\thepage}
- \renewcommand{\headrulewidth}{0.5pt}
- \renewcommand{\footrulewidth}{0.5pt}
---

**********

### Instructions

* Thoroughly analyze the given dataset or data series. Detect any anomalies in each of the variables. Examine if any of the variables that may appear to be top- or bottom-coded.
* Your report needs to include a comprehensive graphical analysis
* Your analysis needs to be accompanied by detailed narrative. Just printing a bunch of graphs and econometric results will likely receive a very low score.
* Your analysis needs to show that your models are valid (in statistical sense).
* Your rationale of using certian metrics to choose models need to be provided. Explain the validity / pros / cons of the metric you use to choose your "best" model.
* Your rationale of any decisions made in your modeling needs to be explained and supported with empirical evidence.
* All the steps to arrive at your final model need to be shown and explained clearly.
* All of the assumptions of your final model need to be thoroughly tested and explained and shown to be valid. Don't just write something like, "the plot looks reasonable", or "the plot looks good", as different people interpret vague terms like "reasonable" or "good" differently.

\pagebreak

```{r, echo = FALSE, warning = FALSE}
require(knitr, quietly = TRUE)
read_chunk('code/W271_Lab3_MS.R')
opts_chunk$set(message = FALSE, warning = FALSE)
opts_chunk$set(fig.width = 4, fig.height = 3)
# Set path to data here (don't use setwd() inside a chunk!!!)
opts_knit$set(root.dir = './data', global.par = TRUE)
```

```{r Libraries-Functions-Constants, echo = FALSE}
```

# Part 1

## Modeling House Values

**In Part 1, you will use the data set `houseValue.csv` to build a linear regression model, which includes the possible use of the instrumental variable approach, to answer a set of questions interested by a philanthropist group. You will also need to test hypotheses using these questions.**

**The philanthropist group hires a think tank to examine the relationship between the house values and neighborhood characteristics. For instance, they are interested in the extent to which houses in neighbhorhood with desirable features command higher values. They are specifically interested in environmental features, such as proximity to water body (i.e. lake, river, or ocean) or air quality of a region.**

**The think tank has collected information from tens of thousands of neighborhoods throughout the United States. They hire your group as contractors, and you are given a small sample and selected variables of the original data set collected to conduct an initial, proof-of-concept analysis. Many variables, in their original form or transfomed forms, that can explain the house values are included in the dataset. Analyze each of these variables as well as different combinations of them very carefully and use them (or a subset of them), in its original or transformed version, to build a linear regression model and test hypotheses to address the questions. Also address potential (statistical) issues that may be casued by omitted variables.**

**********

\pagebreak

**********

\pagebreak

# Part 2

## Modeling and Forecasting a Real-World Macroeconomic / Financial time series

**Build a time-series model for the series in `lab3_series02.csv`, which is extracted from a real-world macroeconomic/financial time series, and use it to perform a 36-step ahead forecast. The periodicity of the series is purposely not provided. Possible models include AR, MA, ARMA, ARIMA, Seasonal ARIMA, GARCH, ARIMA-GARCH, or Seasonal ARIMA-GARCH models.**


We argue that an XXXX model is the best choice. We explored this timeseries data and evaluted possible model types including AR, MA, ARMA, ARIMA, Seasonal ARIMA, GARCH, ARIMA-GARCH, or Seasonal ARIMA-GARCH models. A GARCHXXXXX model was identified as the best fitting model because the time-series is not stationary in the mean or variance and is conditional heteroskedasstic which makes modeling the data using AR, MA, ARMA, ARIMA, or SARIMA models not good fits. 

First we load the data and conduct some exploratory analysis. This includes plotting the timeseries and examining key characteristics that can help us elimate unlikly modeling choices instead of testing all model types.  



```{r ex2-load, echo = -c(1:2)}
```

The file has two columns but the first one is just an incremental index so we discard it. The second column (that is stored in a numeric vector called `DXCM.Close`) contains `r length(d)` observations. No information about the time scale is given so for now we will just index it from 1 to `r length(d)` (with frequency=1). The main descriptive statistics of the series, as well as its histogram and time-series plot are shown below. The histogram is positively skewed with a long tail and far from normal, but as typical with timeseries data the histrogram does not provide information about the dynamics of the series.  


```{r ex2-desc_stats}
```

```{r ex2-hist, echo = FALSE, fig.width = 5, fig.height = 3.75, fig.cap = "Histogram of the data."}
```

We look at the timeseries itself and some zoomed in plots covering approximately the last 1000, 365, 91, and 60 units which could possibly correspond to a year, quarter, and two months. These plots inform us that the time series is not (mean) stationary, as the mean depends on time with an increasing (then slighly decreasing) trend.

```{r ex2-time_plot, echo = 1, fig.width = 5, fig.height = 3.75, fig.cap = "Time-series plot"}
```

```{r ex2-time_plot_zoom, echo = FALSE, fig.height = 2.25, fig.cap = "Zoomed Time-series plots"}
```

We then take a look at the box and whisker plot of the timeseries in order to see if the variance is stationary over time. As we can see in the plot below the variance is not stationary in time and starts to increase over time especially after group 16 in the plot. Note since we do not know the unit of observation we choose to group the data into 22 equal bins of 106 observations in order to be able to identify any changes in variance. We can also plot the square of the timeseries to see if the variance is conditional on the prior and as we can see in the figure below there is a change at around obervation 1700.

```{r ex2-boxplot, echo = FALSE,  fig.width = 5, fig.height = 4, fig.cap = "Boxplot of the series (every 106 observations)."}
```

```{r ex2-square_ts, echo = 1, fig.width = 5, fig.height = 3.75, fig.cap = "Squared Time-series plot"}
```

From the variance analysis above we choose to subset the data and only work with the data from about 1500 to 2332, becasue the data prior to 1500 is likely to not be useful in forcasting the data.

```{r ex2-subset}
```

```{r ex2-sub_time_plot, echo = 1, fig.width = 5, fig.height = 3.75, fig.cap = "Subset Time-series plot"}
```

Since this data is not stationary in the mean or variance; MA, AR, and ARMA models will not be good models to forcast the data. In order to model this non-staionary data we need to difference the data. The plot of the differenced data looks stationary in the mean; however, we also plot the squared ts and notice the variance is still volitile. To confirm our suspicion of conditionally heteroskedastic we plot the ACF of the squared values with adjusted mean. The results in the plot below confirm our suspicion which indicatese that a GARCH style model would be better suited to model the data because they allow for conditional changes in variance. 

```{r ex2-first_diff}
```

```{r ex2-acf, echo = FALSE, fig.width=6, fig.height=4.5, fig.cap = "Autocorrelation Plot"}
```

We now model the data using a GARCH model and look at the confidence intervals, acf, and acf of squared values to examine the residuals. We see that just the GARCH model coefficients are not all statistically significant since zero falls within the the confidence interval of b1. 

```{r ex2-garch}
```

```{r ex2-acf, echo = FALSE, fig.width=6, fig.height=4.5, fig.cap = "Autocorrelation Plots"}
```

**********

\pagebreak

# Part 3

## Forecast the Web Search Activity for global Warming

**Imagine that you group is part of a data science team in an appreal company. One of its recent products is Global-Warming T-shirts. The marketing director expects that the demand for the t-shirts tends to increase when global warming issues are reported in the news. As such, the director asks your group to forecast the level of interest in global warming in the news. The dataset given to your group captures the relative web search activity for the phrase, "global warming" over time. For the purpose of this exercise, ignore the units reported in the data as they are unimportant and irrelevant. Your task is to produce the weekly forecast for the *next 3 months* for the relative web search activity for global warming. For the purpose of this exercise, treat it as a *12-step ahead forecast*.**

**The dataset for this exercise is provided in `globalWarming.csv`. Use only models and techniques covered in the course (up to lecture 13). Note that one of the modeling issues you may have to consider is whether or not to use the entire series provided in the data set. Your choice will have to be clearly explained and supported with empirical evidence. As in other parts of the lab, the general instructions in the *Instruction Section* apply.**


```{r P3-load}
```


```{r P3-timeseries}
```


```{r P3-timeplot_prod, echo=FALSE, fig.width=4, fig.height=3.5}
```

```{r P3-plot_seasonal, echo=FALSE,fig.width=4, fig.height=3.5}
```

As shown in the above figure,  there is no significant change of the interested levels between 2004 and 2012.  After 2012, there is a claer upward trend for the interested level for the globle warming. We extract a subset of data (from 2012 to 2016) for the subsequent study. In term of anaual seasonal change, there are abrupt changes of interest level at the end of June and December.   

```{r P3-acfplot_prod, echo=FALSE, fig.width=7, fig.height=7.5}
```

Instead, similar to the random walk, its ACF does not tail off quickly and many lags are highly correlated. Moreover, the variation in the differenced data series is not stationary as well. Therefore, the global warming data series itself is not stationary. We need to remove the trend and perform transformation of first-order differencing. Besides ACF and PACF plots, we also checked the first-order difference data as well as their ACF and PACF plots. There are still several significant lags observed in ACF and PACF plots of both original and differenced data series. we decided to use arima models to fit the data including certain seasonal effects.

first, we fit the data with the auto.arima function and obtain a complex model (ARIMA(1,1,1)(0,1,1)[52]). We also manually tried serval simple arima models with few parameters and select the best-fit model based on reported AICs. 

```{r P3-best-fit_arima, fig.width=7, fig.height=5}
```

```{r P3-plot-fit_arima, fig.width=6, fig.height=4, echo = -c(1:1)}
```

```{r P3-best-aic_arima}
```

According to the above aic values, we select arima(2,1,2) for further diagnostic checking.  Both ACF and PACF of arima(2,1,2) model residues show no significant lags.  Moreover, there is no significant labs observed within ACF and PACF plots of its square resudue.  At this satge, we assume the selected simple arima(2,1,2) model is approrpiate for the final prediction as well.

```{r P3-check-aic_arima, echo=FALSE, fig.width=7, fig.height=5}
```

```{r P3-forecast-aic_arima,  fig.width=6, fig.height=4}
```

**********

\pagebreak

# Part 4

## Forecast Inflation-Adjusted Gas Price

**During 2013 amid high gas prices, the Associated Press (AP) published an article about the U.S. inflation-adjusted price of gasoline and U.S. oil production. The article claims that there is "*evidence of no statistical correlation*" between oil production and gas prices. The data was not made publicly available, but comparable data was created using data from the Energy Information Administration. The workspace and data frame `gasOil.Rdata` contains the U.S. oil production (in millions of barrels of oil) and the inflation-adjusted average gas prices (in dollars) over the date range the article indicates.**

**In support of their conclusion, the AP reported a single p-value. You have two tasks for this exericse, and both tasks need the use of the data set `gasOil.Rdata`.**

**Your first task is to recreate the analysis that the AP likely used to reach their conclusion. Thoroughly discuss all of the errors the AP made in their analysis and conclusion.**

**Your second task is to create a more statistically-sound model that can be used to predict/forecast inflation-adjusted gas prices. Use your model to forecast the inflation-adjusted gas prices from 2012 to 2016.**

**********
